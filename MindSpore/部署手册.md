
## 准备

### 镜像源(阿里)

```sh
https://zhuanlan.zhihu.com/p/628870519
```

## 安装指南

（官网安装指南）
https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC1alpha003/softwareinst/instg/instg_0030.html

- Ascend-hdk-910b-npu-driver
- Ascend-hdk-910b-npu-firmware
- Ascend-cann-nnae
- Ascend-cann-toolkit

### （csdn安装教程）
https://blog.csdn.net/weixin_36049506/article/details/135297115

### 固件和驱动（官网下载）
https://www.hiascend.com/hardware/firmware-drivers/community?product=4&model=26&cann=7.0.0.alpha003&driver=1.0.RC3.alpha

```sh
# 安装driver
./Ascend-hdk-910b-npu-driver_23.0.rc3_linux-aarch64.run --full --install-for-all
# 安装firmware
./Ascend-hdk-910b-npu-firmware_6.4.0.4.220.run --full
```

### CANN下载
https://www.hiascend.com/developer/download/community/result?module=cann&cann=7.0.0.beta1&product=4&model=26

```sh
# 安装
./Ascend-cann-toolkit_7.0.0_linux-aarch64.run --full --install-for-all
```

### 安装mindspore
https://www.mindspore.cn/install/


## 安装Conda

```sh
conda config --show channels

conda env list

conda activate mindspore_py39
```

### py依赖

```
Package                Version
---------------------- -----------
absl-py                2.1.0
annotated-types        0.6.0
anyio                  4.3.0
asttokens              2.4.1
astunparse             1.6.3
attrs                  23.2.0
auto-tune              0.1.0
certifi                2024.2.2
cffi                   1.16.0
charset-normalizer     3.3.2
click                  8.1.7
dataflow               0.0.1
decorator              5.1.1
exceptiongroup         1.2.0
fastapi                0.110.0
filelock               3.13.3
fsspec                 2024.3.1
ftfy                   6.2.0
h11                    0.14.0
hccl                   0.1.0
hccl-parser            0.1
huggingface-hub        0.22.2
idna                   3.6
importlib_metadata     7.1.0
jieba                  0.42.1
Jinja2                 3.1.3
joblib                 1.3.2
latex2mathml           3.77.0
Markdown               3.6
MarkupSafe             2.1.5
mdtex2html             1.3.0
mindformers            1.1.0
mindpet                1.0.4
mindspore              2.2.11
mpmath                 1.3.0
msadvisor              1.0.0
networkx               3.2.1
nltk                   3.8.1
numpy                  1.26.4
op-compile-tool        0.1.0
op-gen                 0.1
op-test-frame          0.1
opc-tool               0.1.0
opencv-python-headless 4.9.0.80
packaging              24.0
pathlib2               2.3.7.post1
pillow                 10.3.0
pip                    24.0
protobuf               3.20.0
psutil                 5.9.8
pyarrow                12.0.1
pycparser              2.22
pydantic               2.6.4
pydantic_core          2.16.3
PyYAML                 6.0.1
regex                  2023.12.25
requests               2.31.0
rouge-chinese          1.0.3
safetensors            0.4.2
schedule-search        0.0.1
scipy                  1.13.0
sentencepiece          0.2.0
setuptools             69.2.0
six                    1.16.0
sniffio                1.3.1
starlette              0.36.3
sympy                  1.5.1
te                     0.4.0
tiktoken               0.6.0
tokenizers             0.15.0
torch                  2.1.0
torch-npu              2.1.0rc1
torchvision            0.16.0
tqdm                   4.66.2
transformers           4.39.3
typing_extensions      4.11.0
urllib3                2.2.1
uvicorn                0.29.0
wcwidth                0.2.13
wheel                  0.43.0
zipp                   3.18.1
```


## 权重合并

```python
from transformers import AutoTokenizer, AutoModel
import torch
tokenizer = AutoTokenizer.from_pretrained("/path/to/THUDM/chatglm3-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("/path/to/THUDM/chatglm3-6b", trust_remote_code=True)
with open("pt_model_arch.txt", "w") as fp:
    print(model, file=fp, flush=True)
with open("pt_ckpt.txt", "w") as fp:
    for name, param in model.named_parameters():
        fp.write(f"{name} {param.shape} {param.dtype}\n")
torch.save(model.state_dict(), "glm3_6b.pth")
```

## 权重转换

```python
import mindspore as ms
import torch as pt
from tqdm import tqdm
pt_ckpt_path = "glm3_6b.pth"
pt_param = pt.load(pt_ckpt_path)
type_map = {"torch.float16": "ms.float16",
            "torch.float32": "ms.float32"}
ms_param = []
with open("check_pt_ckpt.txt", "w") as fp:
    for k, v in tqdm(pt_param.items()):
        if "word_embeddings.weight" in k:
            k = k.replace("word_embeddings.weight", "embedding_table")
        fp.write(f"{k} {v.shape} {v.dtype}\n")
        ms_param.append({"name": k, "data": ms.Tensor(v.numpy())})
ms.save_checkpoint(ms_param, "glm3_6b.ckpt")
```

## 网络配置

当进行分布式训练时，需要通过昇腾软件中的HCCN Tool工具配置device的网卡IP，用于多个device间通信以实现网络模型参数的同步更新。

对于配置的要求如下：

- AI Server中的第0/4，1/5，2/6，3/7号网卡需处于同一网段，第0/1/2/3号网卡在不同网段，第4/5/6/7号网卡在不同网段。
- 对于集群场景，各AI Server对应的位置的device需处于同一网段，例如：AI Server1和AI Server2的0号网卡需处于同一网段，AI Server1 和 AI Server2 的1号网卡需处于同一网段。IP地址需要根据实际情况修改。

先检查/etc/下是否有hccn.conf配置文件，若不存在，需先执行如下命令进行设置：

```sh
hccn_tool -i 0 -ip -s address 192.168.0.2 netmask 255.255.255.0
hccn_tool -i 1 -ip -s address 192.168.4.2 netmask 255.255.255.0
hccn_tool -i 2 -ip -s address 192.168.2.2 netmask 255.255.255.0
hccn_tool -i 3 -ip -s address 192.168.3.2 netmask 255.255.255.0
hccn_tool -i 4 -ip -s address 192.168.0.3 netmask 255.255.255.0
hccn_tool -i 5 -ip -s address 192.168.4.3 netmask 255.255.255.0
hccn_tool -i 6 -ip -s address 192.168.2.3 netmask 255.255.255.0
hccn_tool -i 7 -ip -s address 192.168.3.3 netmask 255.255.255.0
```

参数说明：

- `-i 0`：指定设备ID。
- `-netdetect`：指定网络检测对象IP属性。
- `-s address`：表示设置属性为IP地址。`192.168.100.101`表示服务器的设备0的ip地址。

查看`/etc/hccn.conf`文件：

```sh
> cat /etc/hccn.conf 
address_0=192.168.100.101 
netmask_0=255.255.255.0 
... 
address_7=192.168.103.100 
netmask_7=255.255.255.0
```
## 启动

- run_mode
	- train 训练
	- finetune 微调
	- eval 评估
	- predict 推理
	- export

```sh
export GRAPH_OP_RUN=1
export MS_ENABLE_INTERNAL_KERNELS=on

# 单卡
python run_mindformer.py --use_parallel=False --config checkpoint_download/glm3/run_glm3_6b.yaml --run_mode predict --predict_data "[gMASK]sop<|user|> \n 你好<|assistant|> \n"
```

## 配置

```sh
# 本地词表
/home/HwHiAiUser/mindformers/checkpoint_download/glm3/tokenizer.model
/home/HwHiAiUser/mindformers/checkpoint_download/glm3/glm3_6b.yaml

# 本地model
/home/HwHiAiUser/model/chatglm3-6b/glm3_6b.ckpt

# 推理
/home/HwHiAiUser/mindformers/configs/glm3/predict_glm3_6b.yaml
/home/HwHiAiUser/mindformers/configs/glm3/my_run_glm3_6b.yaml

# ms
/home/HwHiAiUser/model/chatglm3-6b_ms
/home/HwHiAiUser/model/chatglm3-6b_ms/run_glm3_6b.yaml
```

## 推理

参考 [昇腾910b部署Chatglm3-6b进行流式输出【pytorch框架】NPU推理](https://blog.csdn.net/weixin_46398647/article/details/135459421) （模型权重转换前）